# [llm]
# provider = "ollama"
# model = "llama3.1:8b"

# [embedding]
# provider = "ollama"
# model = "nomic-embed-text"

[llm]
provider = "openai" 
model = "gpt-4o-mini"

[embedding]
provider = "openai" 
model = "text-embedding-3-small"

[vectorDB]
dim = 1536

[chunking]
chunkSize = 300
overlap = 60
minChunkChars = 150

[retrieval]
vectorTopK = 20
bm25TopK = 20
rerankTopK = 10
contextTopK = 5

[reranker]
model = "cross-encoder/ms-marco-MiniLM-L-6-v2"
topK = 10

[conversation]
maxHistory = 10
systemPrompt = "You are a helpful assistant that can only answer questions from the context provided. Use conversation history to understant the references and context"
