[embedding]
model = "text-embedding-3-small"

[vectorDB]
dim = 1536

[generation]
model = "gpt-4o-mini"

[chunking]
chunkSize = 500
overlap = 100
minChunkChars = 200

[retrieval]
vectorTopK = 20
bm25TopK = 20
rerankTopK = 10
contextTopK = 5

[reranker]
model = "cross-encoder/ms-marco-MiniLM-L-6-v2"
topK = 10

[conversation]
maxHistory = 10
systemPrompt = "You are a helpful assistant that can only answer questions from the context provided. Use conversation history to understant the references and context"